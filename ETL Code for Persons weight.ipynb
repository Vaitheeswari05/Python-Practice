{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6f0dfbed-a9be-4f9c-af1b-4ba8e7a5f8d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import zipfile\n",
    "import shutil\n",
    "import os\n",
    "import glob\n",
    "import pandas as pd\n",
    "import xml.etree.ElementTree as ET \n",
    "from datetime import datetime \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "44268de9-8419-4f67-bf81-9cd414565086",
   "metadata": {},
   "outputs": [],
   "source": [
    "url='https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/IBMDeveloperSkillsNetwork-PY0221EN-SkillsNetwork/labs/module%206/Lab%20-%20Extract%20Transform%20Load/data/source.zip'\n",
    "response=requests.get(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9c5d3c38-89fd-4239-8a02-c775d744e92f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File downloaded and extracted successfully.\n"
     ]
    }
   ],
   "source": [
    "if response.status_code == 200:\n",
    "    # Save the content of the response to a file\n",
    "    with open('source.zip', 'wb') as f:\n",
    "        f.write(response.content)\n",
    "\n",
    "    # Extract the contents of the zip file\n",
    "    with zipfile.ZipFile('source.zip', 'r') as zip_ref:\n",
    "        zip_ref.extractall('source')\n",
    "\n",
    "    # Delete the zip file after extraction\n",
    "    os.remove('source.zip')\n",
    "\n",
    "    print(\"File downloaded and extracted successfully.\")\n",
    "else:\n",
    "    print(\"Failed to download the file.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7a4cdd0a-ff7c-4cde-9a33-75b3bc176b9c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['source1.csv',\n",
       " 'source1.json',\n",
       " 'source1.xml',\n",
       " 'source2.csv',\n",
       " 'source2.json',\n",
       " 'source2.xml',\n",
       " 'source3.csv',\n",
       " 'source3.json',\n",
       " 'source3.xml']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "directory = 'source'\n",
    "os.listdir(directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3d68c163-55b8-466a-b435-3e49fb3f79b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#These are transformed_data.csv, to store the final output data that you can load to a database, and log_file.txt, that stores all the logs.\n",
    "#Introduce these paths in the code by adding the following statements:\n",
    "log_file = \"log_file.txt\" \n",
    "target_file = \"transformed_data.csv\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "46154e7d-7059-4cbf-b9f7-e25d3a6dd053",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function for extract the csv file\n",
    "def extract_from_csv(file_to_process): \n",
    "    dataframe = pd.read_csv(file_to_process)\n",
    "    return dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bbb441e7-4a79-4337-a292-1e664c53b7ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function for extract the json file\n",
    "def extract_from_json(file_to_process): \n",
    "    dataframe = pd.read_json(file_to_process, lines=True) \n",
    "    return dataframe "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b4915350-6f97-4160-abc0-70b44d56f9e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function for extract the xml file\n",
    "def extract_from_xml(file_to_process): \n",
    "    dataframe = pd.DataFrame(columns=[\"name\", \"height\", \"weight\"]) \n",
    "    tree = ET.parse(file_to_process) \n",
    "    root = tree.getroot() \n",
    "    for person in root: \n",
    "        name = person.find(\"name\").text\n",
    "        height = float(person.find(\"height\").text) \n",
    "        weight = float(person.find(\"weight\").text) \n",
    "        dataframe = pd.concat([dataframe, pd.DataFrame([{\"name\":name, \"height\":height, \"weight\":weight}])], ignore_index=True) \n",
    "    return dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bc22b9b-8b63-46ad-94c8-f6177cf9b916",
   "metadata": {},
   "source": [
    "To call the relevant function, write a function extract, which uses the glob library to identify the filetype. This can be done as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fcc1c524-b66a-42d2-a87f-9793dc2e77b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract(): \n",
    "    extracted_data = pd.DataFrame(columns=['name','height','weight']) # create an empty data frame to hold extracted data \n",
    "     \n",
    "    # process all csv files \n",
    "    for csvfile in glob.glob(\"*.csv\"): \n",
    "        extracted_data = pd.concat([extracted_data, pd.DataFrame(extract_from_csv(csvfile))], ignore_index=True) \n",
    "         \n",
    "    # process all json files \n",
    "    for jsonfile in glob.glob(\"*.json\"):\n",
    "        extracted_data = pd.concat([extracted_data, pd.DataFrame(extract_from_json(jsonfile))], ignore_index=True) \n",
    "     \n",
    "    # process all xml files \n",
    "    for xmlfile in glob.glob(\"*.xml\"): \n",
    "        extracted_data = pd.concat([extracted_data, pd.DataFrame(extract_from_xml(xmlfile))], ignore_index=True) \n",
    "         \n",
    "    return extracted_data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0d76abca-e1e5-4745-b8e5-c8d68b5781f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Transfered the extracted files\n",
    "def transform(data): \n",
    "    '''Convert inches to meters and round off to two decimals \n",
    "    1 inch is 0.0254 meters '''\n",
    "    data['height'] = round(data.height * 0.0254,2) \n",
    " \n",
    "    '''Convert pounds to kilograms and round off to two decimals \n",
    "    1 pound is 0.45359237 kilograms '''\n",
    "    data['weight'] = round(data.weight * 0.45359237,2) \n",
    "    \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "db7c081d-86ca-4b24-87e3-0c3c42cf33a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(target_file, transformed_data): \n",
    "    transformed_data.to_csv(target_file) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "742cc9c6-a404-4bca-badc-11c8df8445db",
   "metadata": {},
   "outputs": [],
   "source": [
    "def log_progress(message): \n",
    "    timestamp_format = '%Y-%h-%d-%H:%M:%S' # Year-Monthname-Day-Hour-Minute-Second \n",
    "    now = datetime.now() # get current timestamp \n",
    "    timestamp = now.strftime(timestamp_format) \n",
    "    with open(log_file,\"a\") as f: \n",
    "        f.write(timestamp + ',' + message + '\\n') "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "301f2cad-0156-41e0-bed7-070a8be80309",
   "metadata": {},
   "source": [
    "ETL operations and log progress"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a429cab9-f8f6-4c21-9235-516fc82e4c12",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transformed Data\n",
      "Empty DataFrame\n",
      "Columns: [name, height, weight, Unnamed: 0]\n",
      "Index: []\n"
     ]
    }
   ],
   "source": [
    "#ETL operations and log progress\n",
    "# Log the initialization of the ETL process \n",
    "log_progress(\"ETL Job Started\") \n",
    " \n",
    "# Log the beginning of the Extraction process \n",
    "log_progress(\"Extract phase Started\") \n",
    "extracted_data = extract()\n",
    " \n",
    "# Log the completion of the Extraction process \n",
    "log_progress(\"Extract phase Ended\") \n",
    " \n",
    "# Log the beginning of the Transformation process \n",
    "log_progress(\"Transform phase Started\") \n",
    "transformed_data = transform(extracted_data) \n",
    "print(\"Transformed Data\") \n",
    "print(transformed_data) \n",
    " \n",
    "# Log the completion of the Transformation process \n",
    "log_progress(\"Transform phase Ended\") \n",
    " \n",
    "# Log the beginning of the Loading process \n",
    "log_progress(\"Load phase Started\") \n",
    "load_data(target_file,transformed_data) \n",
    " \n",
    "# Log the completion of the Loading process \n",
    "log_progress(\"Load phase Ended\") \n",
    " \n",
    "# Log the completion of the ETL process \n",
    "log_progress(\"ETL Job Ended\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5542046-38c5-4f91-8890-dcdbcf6e4694",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
